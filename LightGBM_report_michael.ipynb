{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415fcc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: polars in /home/mig009/.local/lib/python3.9/site-packages (0.20.22)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in /home/mig009/.local/lib/python3.9/site-packages (4.3.0)\n",
      "Requirement already satisfied: scipy in /home/mig009/.local/lib/python3.9/site-packages (from lightgbm) (1.13.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.22.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dask in /home/mig009/.local/lib/python3.9/site-packages (2024.4.2)\n",
      "Requirement already satisfied: pandas in /home/mig009/.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from dask) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from dask) (23.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.9/site-packages (from dask) (7.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.9/site-packages (from dask) (5.4.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from dask) (0.11.1)\n",
      "Requirement already satisfied: click>=8.1 in /home/mig009/.local/lib/python3.9/site-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from dask) (1.6.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.9/site-packages (from dask) (2024.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.13.0->dask) (3.5.0)\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.9/site-packages (from partd>=1.2.0->dask) (0.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install polars\n",
    "!pip install lightgbm\n",
    "!pip install --upgrade dask pandas\n",
    "\n",
    "# standard library imports\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# third party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import polars as pl\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    SCORERS, \n",
    "    get_scorer,\n",
    "    classification_report, \n",
    "    ConfusionMatrixDisplay, \n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, f1_score, log_loss, get_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# will probably need these later:\n",
    "\n",
    "# import torch\n",
    "# from adapters import AutoAdapterModel\n",
    "# from joblib import dump, load\n",
    "# from pytorch_lightning import Trainer, LightningModule\n",
    "\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from tqdm import tqdm\n",
    "# from transformers import (\n",
    "#     AdamW, \n",
    "#     AutoTokenizer, \n",
    "#     RobertaForSequenceClassification, \n",
    "#     get_linear_schedule_with_warmup\n",
    "# )\n",
    "\n",
    "dataPath = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d3dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/public/home-credit-credit-risk-model-stability/csv_files/train/train_base.csv\")\n",
    "df_test = pd.read_csv(\"~/public/home-credit-credit-risk-model-stability/csv_files/test/test_base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eedb0bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>date_decision</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK_NUM</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id date_decision   MONTH  WEEK_NUM  target\n",
       "0        0    2019-01-03  201901         0       0\n",
       "1        1    2019-01-03  201901         0       0\n",
       "2        2    2019-01-04  201901         0       0\n",
       "3        3    2019-01-03  201901         0       0\n",
       "4        4    2019-01-04  201901         0       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8d332",
   "metadata": {},
   "source": [
    "#### Model Development: Training LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8486070c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 47994, number of negative: 1478665\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 371\n",
      "[LightGBM] [Info] Number of data points in the train set: 1526659, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031437 -> initscore=-3.427819\n",
      "[LightGBM] [Info] Start training from score -3.427819\n",
      "Log Loss: 1.0858050385170126\n",
      "AUC: 0.5\n",
      "Macro-Averaged F1-Score: 0.4920151704109108\n",
      "Confusion Matrix:\n",
      "[[1478665       0]\n",
      " [  47994       0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUC': 0.5, 'Macro F-1': 0.4920151704109108, 'log_loss': 1.0858050385170126}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the pipeline for LightGBM\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer,  ['case_id', 'MONTH', 'WEEK_NUM']),\n",
    "        ('cat', categorical_transformer,  [])])  # Since there are no categorical features in this example\n",
    "\n",
    "lgbm_pipe = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', preprocessor),\n",
    "        (\"clf\", LGBMClassifier(random_state=0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = df[['case_id', 'MONTH', 'WEEK_NUM']]  # Remove 'target' from X_train\n",
    "y_train = df['target']\n",
    "\n",
    "# Train LightGBM model\n",
    "lgbm_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Function to generate report using LightGBM model\n",
    "def generate_report(mdl, df, cols, extra_metrics=None):\n",
    "    '''Takes in a trained model, pandas dataframe of a subset of the test data, \n",
    "    and list of columns to be used in the model.\n",
    "    If necessary, can include a list of other metrics to be outputted, but default is None.\n",
    "    Returns a dictionary of the following breakdown of scores: AUC, F1-Score, and any extra metrics\n",
    "    '''\n",
    "    X_test, y_test = df[cols], df[\"target\"]\n",
    "    y_pred = mdl.predict(X_test)\n",
    "    \n",
    "    res = dict()\n",
    "    res['AUC'] = roc_auc_score(y_test, y_pred)\n",
    "    res['Macro F-1'] = f1_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "    for metric in (extra_metrics or []):\n",
    "        if metric == 'log_loss':\n",
    "            res[metric] = log_loss(y_test, y_pred)\n",
    "            print(f\"Log Loss: {log_loss(y_test, y_pred)}\")\n",
    "        else:\n",
    "            res[metric] = get_scorer(metric)._score_func(y_test, y_pred)\n",
    "            print(f\"{metric}: {get_scorer(metric)._score_func(y_test, y_pred)}\")\n",
    "        \n",
    "    # Results\n",
    "    print(f\"AUC: {roc_auc_score(y_test, y_pred)}\")\n",
    "    print(f\"Macro-Averaged F1-Score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "        \n",
    "    return res\n",
    "\n",
    "# Generate report using LightGBM model\n",
    "generate_report(lgbm_pipe, df, ['case_id', 'MONTH', 'WEEK_NUM'], ['log_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8d3fa",
   "metadata": {},
   "source": [
    "#### Evaluation / Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
